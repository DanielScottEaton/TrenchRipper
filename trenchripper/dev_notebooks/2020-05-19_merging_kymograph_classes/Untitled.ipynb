{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider, IntSlider, Dropdown, IntText, SelectMultiple, Select, IntRangeSlider, FloatRangeSlider\n",
    "from skimage import filters,transform\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.kymograph import kymograph_cluster\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.segment import fluo_segmentation\n",
    "from paulssonlab.deaton.trenchripper.trenchripper.utils import kymo_handle,pandas_hdf5_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de64/paulssonlab/paulssonlab/src/paulssonlab/deaton/trenchripper/trenchripper/utils.py:92: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.metadata = store.get_storer(key).attrs.metadata\n"
     ]
    }
   ],
   "source": [
    "meta_handle = pandas_hdf5_handler(\"/n/scratch2/de64/2019-05-31_validation_data/metadata.hdf5\")\n",
    "test = meta_handle.read_df(\"global\",read_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>File Index</th>\n",
       "      <th>Image Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fov</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>7.121855</td>\n",
       "      <td>5930.8</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5304.325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729.425951</td>\n",
       "      <td>5931.2</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5304.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1449.502511</td>\n",
       "      <td>5931.3</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5304.175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2169.452807</td>\n",
       "      <td>5930.5</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5304.025</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2889.215855</td>\n",
       "      <td>5930.6</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5304.050</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3609.263015</td>\n",
       "      <td>5930.6</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5303.975</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">36</th>\n",
       "      <th>0</th>\n",
       "      <td>96.977591</td>\n",
       "      <td>-5627.2</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5295.675</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820.531319</td>\n",
       "      <td>-5627.2</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5295.775</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540.855367</td>\n",
       "      <td>-5627.2</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5295.575</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2259.635807</td>\n",
       "      <td>-5627.3</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5295.375</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2980.473335</td>\n",
       "      <td>-5627.3</td>\n",
       "      <td>-3658.7</td>\n",
       "      <td>5295.500</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3700.070135</td>\n",
       "      <td>-5627.5</td>\n",
       "      <td>-3658.6</td>\n",
       "      <td>5295.375</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          t       x       y         z  File Index  Image Index\n",
       "fov timepoints                                                                \n",
       "2   0              7.121855  5930.8 -3658.6  5304.325           0            0\n",
       "    1            729.425951  5931.2 -3658.6  5304.500           0            1\n",
       "    2           1449.502511  5931.3 -3658.7  5304.175           0            2\n",
       "    3           2169.452807  5930.5 -3658.7  5304.025           0            3\n",
       "    4           2889.215855  5930.6 -3658.6  5304.050           0            4\n",
       "    5           3609.263015  5930.6 -3658.6  5303.975           0            5\n",
       "36  0             96.977591 -5627.2 -3658.7  5295.675           6            0\n",
       "    1            820.531319 -5627.2 -3658.7  5295.775           6            1\n",
       "    2           1540.855367 -5627.2 -3658.6  5295.575           6            2\n",
       "    3           2259.635807 -5627.3 -3658.7  5295.375           6            3\n",
       "    4           2980.473335 -5627.3 -3658.7  5295.500           6            4\n",
       "    5           3700.070135 -5627.5 -3658.6  5295.375           6            5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[pd.IndexSlice[[2,36],0:5],:]\n",
    "# df.loc[idx[:,[3,4]],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kymograph_interactive(kymograph_cluster):\n",
    "    def __init__(self,headpath):\n",
    "        \"\"\"The kymograph class is used to generate and visualize kymographs.\n",
    "        The central function of this class is the method 'generate_kymograph',\n",
    "        which takes an hdf5 file of images from a single fov and outputs an\n",
    "        hdf5 file containing kymographs from all detected trenches.\n",
    "\n",
    "        NOTE: I need to revisit the row detection, must ensure there can be no overlap...\n",
    "\n",
    "        Args:\n",
    "        \"\"\"\n",
    "        #break all_channels,fov_list,t_subsample_step=t_subsample_step\n",
    "        super(kymograph_interactive, self).__init__(headpath=headpath)\n",
    "        \n",
    "        self.metadf = self.meta_handle.read_df(\"global\",read_metadata=True)\n",
    "        self.metadata = self.metadf.metadata        \n",
    "        self.fov_list = self.metadf.index.get_level_values(\"fov\").unique().values\n",
    "        self.channels = self.metadata[\"channels\"]\n",
    "        self.timepoints_len = self.metadata[\"num_frames\"]\n",
    "\n",
    "        self.final_params = {}\n",
    "\n",
    "    def view_image(self,fov_idx,t,channel,invert):\n",
    "        img_entry = self.metadf.loc[fov_idx,t]\n",
    "        file_idx = int(img_entry[\"File Index\"])\n",
    "        img_idx = int(img_entry[\"Image Index\"])\n",
    "\n",
    "        with h5py.File(self.headpath + \"/hdf5/hdf5_\" + str(file_idx) + \".hdf5\", \"r\") as infile:\n",
    "            img_arr = infile[channel][img_idx,:,:]\n",
    "        if invert:\n",
    "            img_arr = sk.util.invert(img_arr)\n",
    "        plt.imshow(img_arr,cmap=\"Greys_r\")\n",
    "\n",
    "    def view_image_interactive(self):\n",
    "\n",
    "        interact(self.view_image,fov_idx=Select(description='FOV number:',options=self.fov_list),\\\n",
    "             t=IntSlider(value=0, min=0, max=self.timepoints_len-1, step=1,continuous_update=False),\n",
    "            channel=Dropdown(options=self.channels,value=self.channels[0],description='Channel:',disabled=False),\\\n",
    "            invert=Dropdown(options=[True,False],value=False))\n",
    "\n",
    "#     def import_hdf5(self,i):\n",
    "#         \"\"\"Performs initial import of the hdf5 file to be processed. Converts\n",
    "#         the input hdf5 file's \"channel\" datasets into the first dimension of\n",
    "#         the array, ordered as specified by 'self.all_channels'. Outputs a numpy\n",
    "#         array.\n",
    "\n",
    "#         Args:\n",
    "#             i (int): Specifies the current fov index.\n",
    "\n",
    "#         Returns:\n",
    "#             array: A numpy array containing the hdf5 file image data.\n",
    "#         \"\"\"\n",
    "#         fov = self.fov_list[i]\n",
    "#         fovdf = self.metadf.loc[fov]\n",
    "#         last_idx = fovdf.index.get_level_values(0).unique().tolist()[-1]\n",
    "#         fovdf = fovdf.loc[slice(0,last_idx,self.t_subsample_step),:]\n",
    "#         file_indices = fovdf[\"File Index\"].unique().tolist()\n",
    "\n",
    "#         channel_list = []\n",
    "#         for channel in self.all_channels:\n",
    "#             file_list = []\n",
    "#             for j,file_idx in enumerate(file_indices):\n",
    "#                 filedf = fovdf[fovdf[\"File Index\"]==file_idx]\n",
    "#                 img_indices = filedf[\"Image Index\"].unique().tolist()\n",
    "#                 with h5py.File(self.headpath + \"/hdf5/hdf5_\" + str(file_idx) + \".hdf5\", \"r\") as infile:\n",
    "#                     file_list += [infile[channel][idx][:,:,np.newaxis] for idx in img_indices]\n",
    "#             channel_list.append(np.concatenate(file_list,axis=2))\n",
    "#         channel_array = np.array(channel_list)\n",
    "#         if self.invert:\n",
    "#             channel_array = sk.util.invert(channel_array)\n",
    "#         return channel_array\n",
    "\n",
    "#         writedir(self.kymographpath,overwrite=True)\n",
    "#         ### smoothed y percentiles ###\n",
    "\n",
    "#         self.fovdf = self.meta_handle.read_df(\"global\",read_metadata=True)\n",
    "#         self.metadata = self.fovdf.metadata        \n",
    "#         self.filedf = self.fovdf.reset_index(inplace=False)\n",
    "#         self.filedf = self.filedf.set_index([\"File Index\",\"Image Index\"], drop=True, append=False, inplace=False)\n",
    "#         self.filedf = self.filedf.sort_index()        \n",
    "#         self.file_list = self.filedf.index.get_level_values(\"File Index\").unique().values\n",
    "#         self.fov_list = self.fovdf.index.get_level_values(\"fov\").unique().values\n",
    "        \n",
    "    def import_hdf5_files(self,all_channels,seg_channel,invert,fov_list,t_subsample_step):\n",
    "        seg_channel_idx = all_channels.index(seg_channel)\n",
    "        all_channels.insert(0, all_channels.pop(seg_channel_idx))\n",
    "        self.all_channels = all_channels\n",
    "        self.seg_channel = all_channels[0]\n",
    "        self.fov_list = fov_list\n",
    "        self.t_subsample_step = t_subsample_step\n",
    "        self.invert = invert\n",
    "        \n",
    "        self.fovdf = self.meta_handle.read_df(\"global\",read_metadata=True)\n",
    "        self.fovdf = self.fovdf.loc[pd.IndexSlice[self.fov_list,::self.t_subsample_step],:]\n",
    "        \n",
    "        self.filedf = self.fovdf.reset_index(inplace=False)\n",
    "        self.filedf = self.filedf.set_index([\"File Index\",\"Image Index\"], drop=True, append=False, inplace=False)\n",
    "        self.filedf = self.filedf.sort_index()        \n",
    "        self.file_list = self.filedf.index.get_level_values(\"File Index\").unique().values\n",
    "\n",
    "    def import_hdf5_interactive(self):\n",
    "        import_hdf5 = interactive(self.import_hdf5_files, {\"manual\":True}, all_channels=fixed(self.channels),\\\n",
    "                                  seg_channel=Dropdown(options=self.channels, value=self.channels[0]),invert=Dropdown(options=[True,False],\\\n",
    "                                  value=False), fov_list=SelectMultiple(options=self.fov_list),t_subsample_step=IntSlider(value=10,\\\n",
    "                                  min=0, max=200, step=1));\n",
    "        display(import_hdf5)\n",
    "        \n",
    "#         for k,file_idx in enumerate(file_list):\n",
    "#             future = dask_controller.daskclient.submit(self.get_smoothed_y_percentiles,file_idx,\\\n",
    "#                                         self.y_percentile,self.smoothing_kernel_y,retries=1)\n",
    "#             dask_controller.futures[\"Smoothed Y Percentiles: \" + str(file_idx)] = future\n",
    "\n",
    "        \n",
    "#             def get_smoothed_y_percentiles(self,file_idx,y_percentile,smoothing_kernel_y):\n",
    "#         \"\"\"For each imported array, computes the percentile along the x-axis of\n",
    "#         the segmentation channel, generating a (y,t) array. Then performs\n",
    "#         median filtering of this array for smoothing.\n",
    "\n",
    "#         Args:\n",
    "#             imported_hdf5_handle (h5py.File): Hdf5 file handle corresponding to the input hdf5 dataset\n",
    "#             \"data\" of shape (channel,y,x,t).\n",
    "#             y_percentile (int): Percentile to apply along the x-axis.\n",
    "#             smoothing_kernel_y (tuple): Kernel to use for median filtering.\n",
    "\n",
    "#         Returns:\n",
    "#             h5py.File: Hdf5 file handle corresponding to the output hdf5 dataset \"data\", a smoothed\n",
    "#             percentile array of shape (y,t).\n",
    "#         \"\"\"\n",
    "#         with h5py_cache.File(self.hdf5path+\"/hdf5_\"+str(file_idx)+\".hdf5\",\"r\",chunk_cache_mem_size=self.metadata[\"chunk_cache_mem_size\"]) as imported_hdf5_handle:\n",
    "#             img_arr = imported_hdf5_handle[self.seg_channel][:] #t x y\n",
    "#             if self.invert:\n",
    "#                 img_arr = sk.util.invert(img_arr)\n",
    "#             perc_arr = np.percentile(img_arr,y_percentile,axis=2,interpolation='lower')\n",
    "#             y_percentiles_smoothed = self.median_filter_2d(perc_arr,smoothing_kernel_y)\n",
    "\n",
    "#             min_qth_percentile = y_percentiles_smoothed.min(axis=1)[:, np.newaxis]\n",
    "#             max_qth_percentile = y_percentiles_smoothed.max(axis=1)[:, np.newaxis]\n",
    "#             y_percentiles_smoothed = (y_percentiles_smoothed - min_qth_percentile)/(max_qth_percentile - min_qth_percentile)\n",
    "\n",
    "#         return y_percentiles_smoothed\n",
    "        \n",
    "    def preview_y_precentiles(self, y_percentile, smoothing_kernel_y_dim_0,y_percentile_threshold):\n",
    "\n",
    "        self.final_params['Y Percentile'] = y_percentile\n",
    "        self.final_params['Y Smoothing Kernel'] = smoothing_kernel_y_dim_0\n",
    "        self.final_params['Y Percentile Threshold'] = y_percentile_threshold\n",
    "        \n",
    "        y_percentiles_smoothed_list = []\n",
    "        for i, file_idx in enumerate(self.file_list):\n",
    "            y_percentiles_smoothed_list.append(self.get_smoothed_y_percentiles(file_idx,y_percentile,smoothing_kernel_y_dim_0))\n",
    "\n",
    "        y_percentiles_smoothed_list = self.map_to_fovs(self.get_smoothed_y_percentiles,imported_array_list,\\\n",
    "                                                       y_percentile,(smoothing_kernel_y_dim_0,1))\n",
    "\n",
    "        self.plot_y_precentiles(y_percentiles_smoothed_list,self.fov_list,y_percentile_threshold)\n",
    "\n",
    "        self.y_percentiles_smoothed_list = y_percentiles_smoothed_list\n",
    "\n",
    "        return y_percentiles_smoothed_list\n",
    "\n",
    "    def preview_y_precentiles_interactive(self):\n",
    "        row_detection = interactive(self.preview_y_precentiles, {\"manual\":True},\\\n",
    "                        imported_array_list=fixed(self.imported_array_list), y_percentile=IntSlider(value=99,\\\n",
    "                        min=0, max=100, step=1), smoothing_kernel_y_dim_0=IntSlider(value=29, min=1,\\\n",
    "                        max=200, step=2), y_percentile_threshold=FloatSlider(value=0.2, min=0., max=1., step=0.01))\n",
    "        display(row_detection)\n",
    "\n",
    "\n",
    "    def plot_y_precentiles(self,y_percentiles_smoothed_list,fov_list,y_percentile_threshold):\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ### Subplot dimensions of plot\n",
    "        root_list_len = np.ceil(np.sqrt(len(y_percentiles_smoothed_list)))\n",
    "\n",
    "        ### Looping through each fov\n",
    "        idx=0\n",
    "        for j,y_percentiles_smoothed in enumerate(y_percentiles_smoothed_list):\n",
    "            ### Managing Subplots\n",
    "            idx += 1\n",
    "            ax = fig.add_subplot(root_list_len, root_list_len, idx, projection='3d')\n",
    "\n",
    "            ### Making list of vertices (tuples) for use with PolyCollection\n",
    "            vert_arr = np.array([np.add.accumulate(np.ones(y_percentiles_smoothed.shape,dtype=int),axis=0),y_percentiles_smoothed])\n",
    "            verts = []\n",
    "            for t in range(vert_arr.shape[2]):\n",
    "                w_vert = vert_arr[:,:,t]\n",
    "                verts.append([(w_vert[0,i],w_vert[1,i]) for i in range(0,w_vert.shape[1],10)])\n",
    "\n",
    "            ### Making counting array for y position\n",
    "            zs = np.add.accumulate(np.ones(len(verts)))\n",
    "\n",
    "            ### Creating PolyCollection and add to plot\n",
    "            poly = PolyCollection(verts,facecolors = ['b'])\n",
    "            poly.set_alpha(0.5)\n",
    "            ax.add_collection3d(poly,zs=zs, zdir='y')\n",
    "\n",
    "            ### Depecting thresholds as straight lines\n",
    "            x_len = y_percentiles_smoothed.shape[0]\n",
    "            y_len = y_percentiles_smoothed.shape[1]\n",
    "            thr_x = np.repeat(np.add.accumulate(np.ones(x_len,dtype=int))[:,np.newaxis],y_len,axis=1).T.flatten()\n",
    "            thr_y = np.repeat(np.add.accumulate(np.ones(y_len,dtype=int)),x_len)\n",
    "            thr_z = np.repeat(y_percentile_threshold,x_len*y_len)\n",
    "\n",
    "            for i in range(0,x_len*y_len,x_len):\n",
    "                ax.plot(thr_x[i:i+x_len],thr_y[i:i+x_len],thr_z[i:i+x_len],c='r')\n",
    "\n",
    "            ### Plot lebels\n",
    "            ax.set_title(\"FOV: \" + str(fov_list[j]))\n",
    "            ax.set_xlabel('y position')\n",
    "            ax.set_xlim3d(0, vert_arr[0,-1,0])\n",
    "            ax.set_ylabel('time (s)')\n",
    "            ax.set_ylim3d(0, len(verts))\n",
    "            ax.set_zlabel('intensity')\n",
    "            ax.set_zlim3d(0, np.max(vert_arr[1]))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def preview_y_crop(self,y_percentiles_smoothed_list, imported_array_list,y_min_edge_dist, padding_y,\\\n",
    "                       trench_len_y,expected_num_rows,alternate_orientation,orientation_detection,orientation_on_fail,images_per_row):\n",
    "\n",
    "        self.final_params['Minimum Trench Length'] = y_min_edge_dist\n",
    "        self.final_params['Y Padding'] = padding_y\n",
    "        self.final_params['Trench Length'] = trench_len_y\n",
    "        self.final_params['Orientation Detection Method'] = orientation_detection\n",
    "        self.final_params['Expected Number of Rows (Manual Orientation Detection)'] = expected_num_rows\n",
    "        self.final_params['Alternate Orientation'] = alternate_orientation\n",
    "        self.final_params['Top Orientation when Row Drifts Out (Manual Orientation Detection)'] = orientation_on_fail\n",
    "\n",
    "        y_percentile_threshold = self.final_params['Y Percentile Threshold']\n",
    "\n",
    "        get_trench_edges_y_output = self.map_to_fovs(self.get_trench_edges_y,y_percentiles_smoothed_list,y_percentile_threshold)\n",
    "        trench_edges_y_lists = [item[0] for item in get_trench_edges_y_output]\n",
    "        start_above_lists = [item[1] for item in get_trench_edges_y_output]\n",
    "        end_above_lists = [item[2] for item in get_trench_edges_y_output]\n",
    "\n",
    "        get_manual_orientations_output = self.map_to_fovs(self.get_manual_orientations,trench_edges_y_lists,start_above_lists,end_above_lists,\\\n",
    "                                                          alternate_orientation,expected_num_rows,orientation_detection,orientation_on_fail,y_min_edge_dist)\n",
    "\n",
    "        orientations_list = [item[0] for item in get_manual_orientations_output]\n",
    "        drop_first_row_list = [item[1] for item in get_manual_orientations_output]\n",
    "        drop_last_row_list = [item[2] for item in get_manual_orientations_output]\n",
    "\n",
    "        y_ends_lists = self.map_to_fovs(self.get_trench_ends,trench_edges_y_lists,start_above_lists,end_above_lists,orientations_list,drop_first_row_list,drop_last_row_list,y_min_edge_dist)\n",
    "        y_drift_list = self.map_to_fovs(self.get_y_drift,y_ends_lists)\n",
    "\n",
    "        keep_in_frame_kernels_output = self.map_to_fovs(self.keep_in_frame_kernels,y_ends_lists,y_drift_list,imported_array_list,orientations_list,padding_y,trench_len_y)\n",
    "        valid_y_ends_list = [item[0] for item in keep_in_frame_kernels_output]\n",
    "        valid_orientations_list = [item[1] for item in keep_in_frame_kernels_output]\n",
    "        cropped_in_y_list = self.map_to_fovs(self.crop_y,imported_array_list,y_drift_list,valid_y_ends_list,valid_orientations_list,padding_y,trench_len_y)\n",
    "\n",
    "        self.plot_y_crop(cropped_in_y_list,imported_array_list,self.fov_list,valid_orientations_list,images_per_row)\n",
    "\n",
    "        self.cropped_in_y_list = cropped_in_y_list\n",
    "\n",
    "        return cropped_in_y_list\n",
    "\n",
    "    def preview_y_crop_interactive(self):\n",
    "\n",
    "        y_cropping = interactive(self.preview_y_crop,{\"manual\":True},y_percentiles_smoothed_list=fixed(self.y_percentiles_smoothed_list),\\\n",
    "                imported_array_list=fixed(self.imported_array_list),\\\n",
    "                y_min_edge_dist=IntSlider(value=50, min=5, max=1000, step=5),\\\n",
    "                padding_y=IntSlider(value=20, min=0, max=500, step=5),\\\n",
    "                trench_len_y=IntSlider(value=270, min=0, max=1000, step=5),\n",
    "                expected_num_rows=IntText(value=2,description='Number of Rows:',disabled=False),\\\n",
    "                alternate_orientation=Dropdown(options=[True,False],value=True,description='Alternate Orientation?:',disabled=False),\\\n",
    "               orientation_detection=Dropdown(options=[0, 1, 'phase'],value=0,description='Orientation:',disabled=False),\\\n",
    "                orientation_on_fail=Dropdown(options=[None,0, 1],value=0,description='Orientation when < expected rows:',disabled=False),\\\n",
    "                 images_per_row=IntSlider(value=3, min=1, max=10, step=1))\n",
    "\n",
    "        display(y_cropping)\n",
    "\n",
    "    def plot_y_crop(self,cropped_in_y_list,imported_array_list,fov_list,valid_orientations_list,images_per_row):\n",
    "\n",
    "        time_list = range(1,imported_array_list[0].shape[3]+1)\n",
    "        time_per_img = len(time_list)\n",
    "        ttl_lanes = np.sum([len(item) for item in valid_orientations_list])\n",
    "        ttl_imgs = ttl_lanes*time_per_img\n",
    "\n",
    "        remaining_imgs = time_per_img%images_per_row\n",
    "        if remaining_imgs == 0:\n",
    "            rows_per_lane = time_per_img//images_per_row\n",
    "        else:\n",
    "            rows_per_lane = (time_per_img//images_per_row) + 1\n",
    "\n",
    "        nrows = rows_per_lane*ttl_lanes\n",
    "        ncols = images_per_row\n",
    "\n",
    "        fig, _ = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "        idx = 0\n",
    "        for i,cropped_in_y in enumerate(cropped_in_y_list):\n",
    "            num_rows = len(valid_orientations_list[i])\n",
    "            for j in range(num_rows):\n",
    "                for k,t in enumerate(time_list):\n",
    "                    idx += 1\n",
    "                    ax = plt.subplot(nrows,ncols,idx)\n",
    "                    ax.axis(\"off\")\n",
    "                    ax.set_title(\"row=\" + str(j) + \",fov=\" + str(fov_list[i]) + \",t=\" + str(t))\n",
    "                    ax.imshow(cropped_in_y[j,0,:,:,k],cmap=\"Greys_r\")\n",
    "                if remaining_imgs != 0:\n",
    "                    for t in range(0,(images_per_row-remaining_imgs)):\n",
    "                        idx += 1\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "\n",
    "    def preview_x_percentiles(self,cropped_in_y_list, t, x_percentile, background_kernel_x,smoothing_kernel_x,\\\n",
    "                              otsu_scaling,min_threshold):\n",
    "\n",
    "        self.final_params['X Percentile'] = x_percentile\n",
    "        self.final_params['X Background Kernel'] = background_kernel_x\n",
    "        self.final_params['X Smoothing Kernel'] = smoothing_kernel_x\n",
    "        self.final_params['Otsu Threshold Scaling'] = otsu_scaling\n",
    "        self.final_params['Minimum X Threshold'] = min_threshold\n",
    "\n",
    "        smoothed_x_percentiles_list = self.map_to_fovs(self.get_smoothed_x_percentiles,cropped_in_y_list,x_percentile,\\\n",
    "                                                         (background_kernel_x,1),(smoothing_kernel_x,1))\n",
    "        thresholds = []\n",
    "        for smoothed_x_percentiles_row in smoothed_x_percentiles_list:\n",
    "            for smoothed_x_percentiles in smoothed_x_percentiles_row:\n",
    "                x_percentiles_t = smoothed_x_percentiles[:,t]\n",
    "                thresholds.append(self.get_midpoints(x_percentiles_t,otsu_scaling,min_threshold)[1])\n",
    "        self.plot_x_percentiles(smoothed_x_percentiles_list,self.fov_list, t, thresholds)\n",
    "\n",
    "        self.smoothed_x_percentiles_list = smoothed_x_percentiles_list\n",
    "        all_midpoints_list,x_drift_list = self.preview_midpoints(self.smoothed_x_percentiles_list)\n",
    "\n",
    "        return smoothed_x_percentiles_list,all_midpoints_list,x_drift_list\n",
    "\n",
    "    def preview_midpoints(self,smoothed_x_percentiles_list):\n",
    "        otsu_scaling = self.final_params['Otsu Threshold Scaling']\n",
    "        min_threshold = self.final_params['Minimum X Threshold']\n",
    "\n",
    "        all_midpoints_list = self.map_to_fovs(self.get_all_midpoints,self.smoothed_x_percentiles_list,otsu_scaling,min_threshold)\n",
    "        self.plot_midpoints(all_midpoints_list,self.fov_list)\n",
    "        x_drift_list = self.map_to_fovs(self.get_x_drift,all_midpoints_list)\n",
    "\n",
    "        self.all_midpoints_list,self.x_drift_list = (all_midpoints_list,x_drift_list)\n",
    "\n",
    "        return all_midpoints_list,x_drift_list\n",
    "\n",
    "\n",
    "    def preview_x_percentiles_interactive(self):\n",
    "        trench_detection = interactive(self.preview_x_percentiles, {\"manual\":True}, cropped_in_y_list=fixed(self.cropped_in_y_list),t=IntSlider(value=0, min=0, max=self.cropped_in_y_list[0].shape[4]-1, step=1),\\\n",
    "                x_percentile=IntSlider(value=85, min=50, max=100, step=1),background_kernel_x=IntSlider(value=21, min=1, max=601, step=20), smoothing_kernel_x=IntSlider(value=9, min=1, max=31, step=2),\\\n",
    "               otsu_scaling=FloatSlider(value=0.25, min=0., max=2., step=0.01),min_threshold=IntSlider(value=0, min=0., max=65535, step=1));\n",
    "\n",
    "        display(trench_detection)\n",
    "\n",
    "    def plot_x_percentiles(self,smoothed_x_percentiles_list,fov_list,t,thresholds):\n",
    "        fig = plt.figure()\n",
    "        nrow = len(self.cropped_in_y_list) #fovs\n",
    "        ncol = (sum([len(item) for item in self.cropped_in_y_list])//nrow)+1\n",
    "\n",
    "        idx = 0\n",
    "        for i,smoothed_x_percentiles_lanes in enumerate(smoothed_x_percentiles_list):\n",
    "            for j,smoothed_x_percentiles in enumerate(smoothed_x_percentiles_lanes):\n",
    "                idx += 1\n",
    "                data = smoothed_x_percentiles[:,t]\n",
    "                ax = fig.add_subplot(ncol, nrow, idx)\n",
    "                ax.plot(data)\n",
    "\n",
    "                current_threshold = thresholds[idx-1]\n",
    "                threshold_data = np.repeat(current_threshold,len(data))\n",
    "                ax.plot(threshold_data,c='r')\n",
    "                ax.set_title(\"FOV: \" + str(fov_list[i]) + \" Lane: \" + str(j))\n",
    "                ax.set_xlabel('x position')\n",
    "                ax.set_ylabel('intensity')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def plot_midpoints(self,all_midpoints_list,fov_list):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "\n",
    "        nrows = 2*len(fov_list)\n",
    "        ncols = 2\n",
    "\n",
    "        idx = 0\n",
    "        for i,top_bottom_list in enumerate(all_midpoints_list):\n",
    "            for j,all_midpoints in enumerate(top_bottom_list):\n",
    "                idx+=1\n",
    "                ax = plt.subplot(nrows,ncols,idx)\n",
    "                ax.set_title(\"row=\" + str(j) + \",fov=\" + str(fov_list[i]))\n",
    "                data = np.concatenate([np.array([item,np.ones(item.shape,dtype=int)*k]).T for k,item in enumerate(all_midpoints)])\n",
    "                ax.scatter(data[:,0],data[:,1],alpha=0.7)\n",
    "                ax.set_xlabel('x position')\n",
    "                ax.set_ylabel('time')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def preview_kymographs(self,cropped_in_y_list,all_midpoints_list,x_drift_list,trench_width_x,trench_present_thr):\n",
    "        self.final_params['Trench Width'] = trench_width_x\n",
    "        self.final_params['Trench Presence Threshold'] = trench_present_thr\n",
    "\n",
    "        cropped_in_x_list = self.map_to_fovs(self.get_crop_in_x,cropped_in_y_list,all_midpoints_list,x_drift_list,\\\n",
    "                                             trench_width_x,trench_present_thr)\n",
    "        corrected_midpoints_list = self.map_to_fovs(self.get_corrected_midpoints,all_midpoints_list,x_drift_list,trench_width_x,trench_present_thr)\n",
    "\n",
    "        self.plot_kymographs(cropped_in_x_list,self.fov_list)\n",
    "        self.plot_midpoints(corrected_midpoints_list,self.fov_list)\n",
    "\n",
    "    def preview_kymographs_interactive(self):\n",
    "            interact_manual(self.preview_kymographs,cropped_in_y_list=fixed(self.cropped_in_y_list),all_midpoints_list=fixed(self.all_midpoints_list),\\\n",
    "            x_drift_list=fixed(self.x_drift_list),trench_width_x=IntSlider(value=30, min=2, max=1000, step=2),\\\n",
    "            trench_present_thr=FloatSlider(value=0., min=0., max=1., step=0.05))\n",
    "\n",
    "    def plot_kymographs(self,cropped_in_x_list,fov_list,num_rows=2):\n",
    "        plt.figure()\n",
    "        idx = 0\n",
    "        ncol = num_rows\n",
    "        nrow = len(fov_list)*num_rows\n",
    "\n",
    "        for i,row_list in enumerate(cropped_in_x_list):\n",
    "            for j,channel in enumerate(row_list):\n",
    "                seg_channel = channel[0]\n",
    "                idx+=1\n",
    "                rand_k = np.random.randint(0,seg_channel.shape[0])\n",
    "                ax = plt.subplot(ncol,nrow,idx)\n",
    "                ex_kymo = seg_channel[rand_k]\n",
    "                self.plot_kymograph(ax,ex_kymo)\n",
    "                ax.set_title(\"row=\" + str(j) + \",fov=\" + str(fov_list[i]) + \",trench=\" + str(rand_k))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_kymograph(self,ax,kymograph):\n",
    "        \"\"\"Helper function for plotting kymographs. Takes a kymograph array of\n",
    "        shape (y_dim,x_dim,t_dim).\n",
    "\n",
    "        Args:\n",
    "            kymograph (array): kymograph array of shape (y_dim,x_dim,t_dim).\n",
    "        \"\"\"\n",
    "        list_in_t = [kymograph[:,:,t] for t in range(kymograph.shape[2])]\n",
    "        img_arr = np.concatenate(list_in_t,axis=1)\n",
    "        ax.imshow(img_arr,cmap=\"Greys_r\")\n",
    "\n",
    "    def process_results(self):\n",
    "        self.final_params[\"All Channels\"] = self.all_channels\n",
    "        self.final_params[\"Invert\"] = self.invert\n",
    "\n",
    "        for key,value in self.final_params.items():\n",
    "            print(key + \" \" + str(value))\n",
    "\n",
    "    def write_param_file(self):\n",
    "        with open(self.headpath + \"/kymograph.par\", \"wb\") as outfile:\n",
    "            pickle.dump(self.final_params, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
